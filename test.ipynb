{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c431308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_val length=56\n",
      "ds_test length=71\n",
      "\n",
      "SER Accuracy ds_test (speaker [15]) = 0.7678571428571429 \n",
      "\n",
      "SER Accuracy ds_val (speaker [15]) = 0.7678571428571429\n",
      "WAVFILE                        PREDICTED EMOTION\n",
      "\n",
      "fear_sadness.wav                    anger\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from engine import EmoNet, EmoDS, build_emodb, benchmark\n",
    "from config import cfg  # assigns the 10 emodb speakers: 8 in ds_train / 1 in ds_val / 1 in ds_test\n",
    "\n",
    "db = build_emodb(cfg.data_dir)  # list of pairs [wav_file, emotion_id]\n",
    "\n",
    "ds_val = EmoDS(db=db, data_dir=cfg.data_dir, split='val')  # all recording of val speaker (see cfg.speaker_assign)\n",
    "ds_test = EmoDS(db=db, data_dir=cfg.data_dir, split='test')  # all recordings of the test speaker\n",
    "\n",
    "model = EmoNet().to(cfg.dev)  # architecture inspired by wav2letter\n",
    "model.load_state_dict(torch.load(cfg.best_pth))  # load best model\n",
    "model.eval();\n",
    "\n",
    "# # test\n",
    "# print('\\n', *(12*[' ']), 'Confusion ds_test (PREDS x TRUE)\\n')\n",
    "# stats = benchmark(model, ds=ds_test, dev=cfg.dev)\n",
    "# print(stats['confusion'])\n",
    "print(f'\\nSER Accuracy ds_test (speaker {stats[\"speaker\"]}) =', stats['accuracy'],'\\n')\n",
    "\n",
    "# val\n",
    "stats = benchmark(model, ds=ds_val, dev=cfg.dev)\n",
    "print(f'SER Accuracy ds_val (speaker {stats[\"speaker\"]}) =', stats['accuracy'])\n",
    "\n",
    "# predict emotion of my own voice\n",
    "wav_file = 'fear_sadness.wav'  # 16,000 Hz\n",
    "print('WAVFILE                        PREDICTED EMOTION\\n')\n",
    "x, _ = sf.read(filename)\n",
    "x = torch.as_tensor(x[None, None, :], device=cfg.dev, dtype=torch.float)\n",
    "logits = model(x)\n",
    "emotion = cfg.id2name[int(logits.argmax())]\n",
    "print(f'{wav_file:<20} {emotion:>20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e83c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
